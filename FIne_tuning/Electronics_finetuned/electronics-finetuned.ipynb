{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9240914,"sourceType":"datasetVersion","datasetId":5589901}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-25T10:16:18.425330Z","iopub.execute_input":"2024-08-25T10:16:18.425715Z","iopub.status.idle":"2024-08-25T10:16:18.856205Z","shell.execute_reply.started":"2024-08-25T10:16:18.425670Z","shell.execute_reply":"2024-08-25T10:16:18.854255Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/final-concatenation/concatenated_books.txt\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Packages","metadata":{}},{"cell_type":"code","source":"#Installing required packages\n!pip install -q transformers bitsandbytes peft trl accelerate xformers wandb datasets einops","metadata":{"execution":{"iopub.status.busy":"2024-08-25T10:16:18.862760Z","iopub.execute_input":"2024-08-25T10:16:18.863527Z","iopub.status.idle":"2024-08-25T10:16:32.774739Z","shell.execute_reply.started":"2024-08-25T10:16:18.863480Z","shell.execute_reply":"2024-08-25T10:16:32.773418Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"import re ","metadata":{"execution":{"iopub.status.busy":"2024-08-25T10:16:32.776474Z","iopub.execute_input":"2024-08-25T10:16:32.776846Z","iopub.status.idle":"2024-08-25T10:16:32.781972Z","shell.execute_reply.started":"2024-08-25T10:16:32.776807Z","shell.execute_reply":"2024-08-25T10:16:32.780766Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def remove_non_alphanumeric(text):\n    # Use regex to keep alphanumeric characters, spaces, punctuation marks, and the \"=\" sign\n    cleaned_text = re.sub(r'[^a-zA-Z0-9\\s.,!?;:()\\'\"-=]', '', text)\n    return cleaned_text\n\ndef merge_short_paragraphs(text, word_limit=20):\n    paragraphs = [p.strip() for p in text.split(\"\\n\\n\") if p.strip()]\n    merged_paragraphs = []\n    buffer_paragraph = \"\"\n\n    for paragraph in paragraphs:\n        paragraph=remove_non_alphanumeric(paragraph)\n        word_count = len(paragraph.split())\n\n        if word_count < word_limit:\n            buffer_paragraph += \" \" + paragraph\n        else:\n            if buffer_paragraph:\n                merged_paragraphs.append(buffer_paragraph.strip() + \" \" + paragraph)\n                buffer_paragraph = \"\"\n            else:\n                merged_paragraphs.append(paragraph)\n\n    if buffer_paragraph:\n        if merged_paragraphs:\n            merged_paragraphs[-1] += \" \" + buffer_paragraph.strip()\n        else:\n            merged_paragraphs.append(buffer_paragraph.strip())\n\n    return \"\\n\\n\".join(merged_paragraphs)\n\ndef process_file(input_file, output_file, word_limit=20):\n    with open(input_file, 'r', encoding='utf-8') as f:\n        text = f.read()\n\n    processed_text = merge_short_paragraphs(text, word_limit)\n\n    with open(output_file, 'w', encoding='utf-8') as f:\n        f.write(processed_text)\n\n# Example usage\ninput_file = '/kaggle/input/final-concatenation/concatenated_books.txt'\noutput_file = 'output.txt'\nprocess_file(input_file, output_file, word_limit=20)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T10:16:32.784767Z","iopub.execute_input":"2024-08-25T10:16:32.785064Z","iopub.status.idle":"2024-08-25T10:16:33.534725Z","shell.execute_reply.started":"2024-08-25T10:16:32.785030Z","shell.execute_reply":"2024-08-25T10:16:33.533684Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Ban gya dataset Hurray<3","metadata":{}},{"cell_type":"code","source":"import json\nimport re\n\n# Load the text file\nwith open(\"/kaggle/working/output.txt\", \"r\") as file:\n    text = file.read()\n\n# Split the text into paragraphs based on double newlines\nparagraphs = text.split(\"\\n\\n\")\n\n# Create a dataset format\ndataset = []\n\nfor paragraph in paragraphs:\n    # Remove newlines within the paragraph using regex\n    paragraph = re.sub(r'\\n+', ' ', paragraph).strip()\n\n    # Split the paragraph into sentences\n    sentences = re.split(r'(?<=[.!?]) +', paragraph)\n    \n    if len(sentences) < 4:\n        # For paragraphs with fewer than 2 sentences, use the whole paragraph as context and question\n        dataset.append({\n            \"context\": paragraph.strip(),\n            \"question\": paragraph.strip(),\n            \"answer\": paragraph.strip(),\n            \"text\":paragraph.strip()\n        })\n    else:\n        # Determine the split point for question and answer\n        split_point = len(sentences) // 4\n        \n        # Create the \"question\" and \"answer\"\n        question = \" \".join(sentences[:split_point]).strip()\n        answer = \" \".join(sentences[split_point:]).strip()\n        \n        # Add to the dataset\n        dataset.append({\n            \"context\": paragraph.strip(),  # Optional: Use the entire paragraph as context\n            \"question\": question,\n            \"answer\": answer,\n            \"text\":paragraph.strip()\n        })\n\n# Save the dataset as a JSON file\nwith open(\"qa_dataset.json\", \"w\") as outfile:\n    json.dump(dataset, outfile, indent=2)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T10:16:33.536079Z","iopub.execute_input":"2024-08-25T10:16:33.536517Z","iopub.status.idle":"2024-08-25T10:16:34.827471Z","shell.execute_reply.started":"2024-08-25T10:16:33.536468Z","shell.execute_reply":"2024-08-25T10:16:34.826397Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Working on fine tuning","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ndata = load_dataset(\"json\", data_files=\"/kaggle/working/qa_dataset.json\", split=\"train\")\n\nprint(data[300])\nprint(len(data))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T10:16:34.828777Z","iopub.execute_input":"2024-08-25T10:16:34.829071Z","iopub.status.idle":"2024-08-25T10:16:36.356416Z","shell.execute_reply.started":"2024-08-25T10:16:34.829038Z","shell.execute_reply":"2024-08-25T10:16:36.355459Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84d98f848be6454d8be97ac780d40dd4"}},"metadata":{}},{"name":"stdout","text":"{'context': '(d) F I G U R E 2.51 Collapsing the circuit. Now, following the results of Section 2.3.1, or equivalently by applying Ohms law directly, we know that V i1 =  R1 + R2 (R3 +R4 ) R2 +R3 +R4 . Thus, at this point, i0 , v0 , and i1 are known. Our intuitive analysis concludes by expanding the circuit in Figure 2.51d progressively. As we expand, we determine the values of as many of the variables as we can in terms of previously computed variables. Following this process, first, the circuit in Figure 2.51c can be viewed as a voltage divider of v0 . In other words, i1 can be multiplied by each of its two resistances to determine v1 and v2 . Thus, R1', 'question': '(d) F I G U R E 2.51 Collapsing the circuit. Now, following the results of Section 2.3.1, or equivalently by applying Ohms law directly, we know that V i1 =  R1 + R2 (R3 +R4 ) R2 +R3 +R4 .', 'answer': 'Thus, at this point, i0 , v0 , and i1 are known. Our intuitive analysis concludes by expanding the circuit in Figure 2.51d progressively. As we expand, we determine the values of as many of the variables as we can in terms of previously computed variables. Following this process, first, the circuit in Figure 2.51c can be viewed as a voltage divider of v0 . In other words, i1 can be multiplied by each of its two resistances to determine v1 and v2 . Thus, R1', 'text': '(d) F I G U R E 2.51 Collapsing the circuit. Now, following the results of Section 2.3.1, or equivalently by applying Ohms law directly, we know that V i1 =  R1 + R2 (R3 +R4 ) R2 +R3 +R4 . Thus, at this point, i0 , v0 , and i1 are known. Our intuitive analysis concludes by expanding the circuit in Figure 2.51d progressively. As we expand, we determine the values of as many of the variables as we can in terms of previously computed variables. Following this process, first, the circuit in Figure 2.51c can be viewed as a voltage divider of v0 . In other words, i1 can be multiplied by each of its two resistances to determine v1 and v2 . Thus, R1'}\n21088\n","output_type":"stream"}]},{"cell_type":"code","source":"chhota_data = data.select(range(1000))\nprint(chhota_data[2])","metadata":{"execution":{"iopub.status.busy":"2024-08-25T10:16:36.357720Z","iopub.execute_input":"2024-08-25T10:16:36.358040Z","iopub.status.idle":"2024-08-25T10:16:36.365813Z","shell.execute_reply.started":"2024-08-25T10:16:36.358006Z","shell.execute_reply":"2024-08-25T10:16:36.364619Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"{'context': '1. Notice that Newtons laws of physics are themselves based on discretizing matter. Newtons laws describe the dynamics of discrete bodies of matter by treating them as point masses. The spatial distribution of properties within the discrete elements are ignored.', 'question': '1.', 'answer': 'Notice that Newtons laws of physics are themselves based on discretizing matter. Newtons laws describe the dynamics of discrete bodies of matter by treating them as point masses. The spatial distribution of properties within the discrete elements are ignored.', 'text': '1. Notice that Newtons laws of physics are themselves based on discretizing matter. Newtons laws describe the dynamics of discrete bodies of matter by treating them as point masses. The spatial distribution of properties within the discrete elements are ignored.'}\n","output_type":"stream"}]},{"cell_type":"code","source":"print(chhota_data[99])","metadata":{"execution":{"iopub.status.busy":"2024-08-25T10:16:36.366967Z","iopub.execute_input":"2024-08-25T10:16:36.367341Z","iopub.status.idle":"2024-08-25T10:16:36.377121Z","shell.execute_reply.started":"2024-08-25T10:16:36.367296Z","shell.execute_reply":"2024-08-25T10:16:36.376127Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"{'context': '1.6 Ideal Two-Terminal Elements markings inside it, as in Figure 1.26b. If the voltage source supplies a voltage V, then we also include the V symbol inside the circle (or just outside the circle if there is not enough room to write the symbol inside). In the same manner, we might also represent an information source, such as a microphone or a sensor, as a voltage source providing a time-varying voltage v(t) at its output (Figure 1.26c). We can assume that the voltage v(t) depends solely on the microphone signal and is independent of the amount of current drawn from the terminals. ( Note that V and v(t) in Figure 1.26 are element values and not terminal variables.) We will see two types of voltage sources: independent and dependent. An independent voltage source supplies a voltage independent of the rest of the circuit. Accordingly, independent sources are a means through which inputs can be made to a circuit. Power supplies, signal generators, and microphones are examples of independent voltage sources. The circle symbol in Figure 1.26b represents an independent voltage source. In contrast to an independent voltage source, a dependent voltage source supplies a voltage as commanded by a signal from within the circuit of which the source is a part. Dependent sources are most commonly used to model elements having more than two terminals. They are represented with a diamond symbol; we shall see examples of these in future chapters. In a manner similar to our invention of the ideal voltage source, we postulate an ideal conductor to be one in which any amount of current can flow without loss of voltage or power. The symbol for an ideal conductor is shown in Figure 1.27a. Notice that the symbol is just a line. The ideal conductor is no different from the ideal wire we saw earlier. Ideal conductors can be used to represent a channel for fluid flow in hydrodynamic systems. Any physical length of wire will have some nonzero resistance. The resistance dissipates energy and represents a loss of energy from the system. If this resistance is important in a particular application, then we can model the wire as an ideal conductor in series with a resistor, as suggested in Figure 1.27b. To be consistent, we now state that the resistor symbol introduced in Figure 1.19 represents an ideal linear resistor, which by definition obeys Ohms law v = iR', 'question': '1.6 Ideal Two-Terminal Elements markings inside it, as in Figure 1.26b. If the voltage source supplies a voltage V, then we also include the V symbol inside the circle (or just outside the circle if there is not enough room to write the symbol inside). In the same manner, we might also represent an information source, such as a microphone or a sensor, as a voltage source providing a time-varying voltage v(t) at its output (Figure 1.26c). We can assume that the voltage v(t) depends solely on the microphone signal and is independent of the amount of current drawn from the terminals. ( Note that V and v(t) in Figure 1.26 are element values and not terminal variables.) We will see two types of voltage sources: independent and dependent.', 'answer': 'An independent voltage source supplies a voltage independent of the rest of the circuit. Accordingly, independent sources are a means through which inputs can be made to a circuit. Power supplies, signal generators, and microphones are examples of independent voltage sources. The circle symbol in Figure 1.26b represents an independent voltage source. In contrast to an independent voltage source, a dependent voltage source supplies a voltage as commanded by a signal from within the circuit of which the source is a part. Dependent sources are most commonly used to model elements having more than two terminals. They are represented with a diamond symbol; we shall see examples of these in future chapters. In a manner similar to our invention of the ideal voltage source, we postulate an ideal conductor to be one in which any amount of current can flow without loss of voltage or power. The symbol for an ideal conductor is shown in Figure 1.27a. Notice that the symbol is just a line. The ideal conductor is no different from the ideal wire we saw earlier. Ideal conductors can be used to represent a channel for fluid flow in hydrodynamic systems. Any physical length of wire will have some nonzero resistance. The resistance dissipates energy and represents a loss of energy from the system. If this resistance is important in a particular application, then we can model the wire as an ideal conductor in series with a resistor, as suggested in Figure 1.27b. To be consistent, we now state that the resistor symbol introduced in Figure 1.19 represents an ideal linear resistor, which by definition obeys Ohms law v = iR', 'text': '1.6 Ideal Two-Terminal Elements markings inside it, as in Figure 1.26b. If the voltage source supplies a voltage V, then we also include the V symbol inside the circle (or just outside the circle if there is not enough room to write the symbol inside). In the same manner, we might also represent an information source, such as a microphone or a sensor, as a voltage source providing a time-varying voltage v(t) at its output (Figure 1.26c). We can assume that the voltage v(t) depends solely on the microphone signal and is independent of the amount of current drawn from the terminals. ( Note that V and v(t) in Figure 1.26 are element values and not terminal variables.) We will see two types of voltage sources: independent and dependent. An independent voltage source supplies a voltage independent of the rest of the circuit. Accordingly, independent sources are a means through which inputs can be made to a circuit. Power supplies, signal generators, and microphones are examples of independent voltage sources. The circle symbol in Figure 1.26b represents an independent voltage source. In contrast to an independent voltage source, a dependent voltage source supplies a voltage as commanded by a signal from within the circuit of which the source is a part. Dependent sources are most commonly used to model elements having more than two terminals. They are represented with a diamond symbol; we shall see examples of these in future chapters. In a manner similar to our invention of the ideal voltage source, we postulate an ideal conductor to be one in which any amount of current can flow without loss of voltage or power. The symbol for an ideal conductor is shown in Figure 1.27a. Notice that the symbol is just a line. The ideal conductor is no different from the ideal wire we saw earlier. Ideal conductors can be used to represent a channel for fluid flow in hydrodynamic systems. Any physical length of wire will have some nonzero resistance. The resistance dissipates energy and represents a loss of energy from the system. If this resistance is important in a particular application, then we can model the wire as an ideal conductor in series with a resistor, as suggested in Figure 1.27b. To be consistent, we now state that the resistor symbol introduced in Figure 1.19 represents an ideal linear resistor, which by definition obeys Ohms law v = iR'}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Thak gya hu","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\n# Retrieve the token from the environment variable\nsecret_label = \"HF_TOKEN\"\nhf_token = UserSecretsClient().get_secret(secret_label)\nfrom huggingface_hub import login\nlogin(token = hf_token,add_to_git_credential=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T10:16:36.378302Z","iopub.execute_input":"2024-08-25T10:16:36.378596Z","iopub.status.idle":"2024-08-25T10:16:36.686700Z","shell.execute_reply.started":"2024-08-25T10:16:36.378564Z","shell.execute_reply":"2024-08-25T10:16:36.685696Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Token is valid (permission: write).\n\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\nYou might have to re-authenticate when pushing to the Hugging Face Hub.\nRun the following command in your terminal in case you want to set the 'store' credential helper as default.\n\ngit config --global credential.helper store\n\nRead https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\nToken has not been saved to git credential helper.\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"WANDB\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T10:16:36.687914Z","iopub.execute_input":"2024-08-25T10:16:36.688224Z","iopub.status.idle":"2024-08-25T10:16:36.855875Z","shell.execute_reply.started":"2024-08-25T10:16:36.688190Z","shell.execute_reply":"2024-08-25T10:16:36.854853Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#importing library\nfrom huggingface_hub import notebook_login\nfrom datasets import load_dataset, Dataset\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForLanguageModeling, BitsAndBytesConfig, TextStreamer\nfrom peft import LoraConfig, get_peft_model, PeftModel\nimport torch, os, wandb\nwandb.login(key = secret_value_0)\nnew_model = \"Huggingface repository link\"\nbase_model = \"microsoft/phi-2\"","metadata":{"execution":{"iopub.status.busy":"2024-08-25T10:16:36.857259Z","iopub.execute_input":"2024-08-25T10:16:36.857593Z","iopub.status.idle":"2024-08-25T10:16:45.896340Z","shell.execute_reply.started":"2024-08-25T10:16:36.857556Z","shell.execute_reply":"2024-08-25T10:16:45.895409Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjustharshitjaiswal14\u001b[0m (\u001b[33mhavelihunters\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"}]},{"cell_type":"code","source":"#loading the model and tokenizer\nbitsandbytes= BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.float16\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model, device_map={\"\":0},\n    quantization_config= bitsandbytes, trust_remote_code= True\n)\ntokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2024-08-25T10:16:45.897739Z","iopub.execute_input":"2024-08-25T10:16:45.898703Z","iopub.status.idle":"2024-08-25T10:16:49.823418Z","shell.execute_reply.started":"2024-08-25T10:16:45.898629Z","shell.execute_reply":"2024-08-25T10:16:49.822342Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"618d7f539125453e96b59f640af6feec"}},"metadata":{}}]},{"cell_type":"code","source":"run = wandb.init(project='Fine tuning llama3 unsloth', job_type=\"training\", anonymous=\"allow\")","metadata":{"execution":{"iopub.status.busy":"2024-08-25T10:16:49.827064Z","iopub.execute_input":"2024-08-25T10:16:49.827409Z","iopub.status.idle":"2024-08-25T10:17:06.552262Z","shell.execute_reply.started":"2024-08-25T10:16:49.827373Z","shell.execute_reply":"2024-08-25T10:17:06.550680Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240825_101649-po4xbirg</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/havelihunters/Fine%20tuning%20llama3%20unsloth/runs/po4xbirg' target=\"_blank\">copper-sun-15</a></strong> to <a href='https://wandb.ai/havelihunters/Fine%20tuning%20llama3%20unsloth' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/havelihunters/Fine%20tuning%20llama3%20unsloth' target=\"_blank\">https://wandb.ai/havelihunters/Fine%20tuning%20llama3%20unsloth</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/havelihunters/Fine%20tuning%20llama3%20unsloth/runs/po4xbirg' target=\"_blank\">https://wandb.ai/havelihunters/Fine%20tuning%20llama3%20unsloth/runs/po4xbirg</a>"},"metadata":{}}]},{"cell_type":"code","source":"print(model)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T10:17:06.553910Z","iopub.execute_input":"2024-08-25T10:17:06.554243Z","iopub.status.idle":"2024-08-25T10:17:06.564019Z","shell.execute_reply.started":"2024-08-25T10:17:06.554207Z","shell.execute_reply":"2024-08-25T10:17:06.562870Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"PhiForCausalLM(\n  (model): PhiModel(\n    (embed_tokens): Embedding(51200, 2560)\n    (embed_dropout): Dropout(p=0.0, inplace=False)\n    (layers): ModuleList(\n      (0-31): 32 x PhiDecoderLayer(\n        (self_attn): PhiSdpaAttention(\n          (q_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n          (k_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n          (v_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n          (dense): Linear4bit(in_features=2560, out_features=2560, bias=True)\n          (rotary_emb): PhiRotaryEmbedding()\n        )\n        (mlp): PhiMLP(\n          (activation_fn): NewGELUActivation()\n          (fc1): Linear4bit(in_features=2560, out_features=10240, bias=True)\n          (fc2): Linear4bit(in_features=10240, out_features=2560, bias=True)\n        )\n        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n        (resid_dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=2560, out_features=51200, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\nconfig = LoraConfig(\n    r=16,\n    lora_alpha=16,\n    target_modules=[\n        'q_proj',\n        'k_proj',\n        'v_proj',\n        'dense'\n    ],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\nmodel = get_peft_model(model, config)\nmodel.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T10:17:06.565051Z","iopub.execute_input":"2024-08-25T10:17:06.565448Z","iopub.status.idle":"2024-08-25T10:17:06.906536Z","shell.execute_reply.started":"2024-08-25T10:17:06.565394Z","shell.execute_reply":"2024-08-25T10:17:06.905517Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"trainable params: 10,485,760 || all params: 2,790,169,600 || trainable%: 0.3758\n","output_type":"stream"}]},{"cell_type":"code","source":"#Tokenzing the dataset\ndef tok(sample):\n    model_inps =  tokenizer(sample[\"text\"], padding=True)\n    return model_inps\n# data = load_dataset(\"vicgalle/alpaca-gpt4\", split=\"train\")\ntokenized_training_data = chhota_data.map(tok, batched=True)\ntokenized_training_data","metadata":{"execution":{"iopub.status.busy":"2024-08-25T10:17:06.908102Z","iopub.execute_input":"2024-08-25T10:17:06.908797Z","iopub.status.idle":"2024-08-25T10:17:07.574270Z","shell.execute_reply.started":"2024-08-25T10:17:06.908759Z","shell.execute_reply":"2024-08-25T10:17:07.573172Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb62a47ae9314bb3ad58952e9108bdbd"}},"metadata":{}},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['context', 'question', 'answer', 'text', 'input_ids', 'attention_mask'],\n    num_rows: 1000\n})"},"metadata":{}}]},{"cell_type":"code","source":"#Training hyperparamters\ntraining_arguments = TrainingArguments(\n        output_dir=\"output\",\n        per_device_train_batch_size=2,\n        gradient_accumulation_steps=2,\n        learning_rate=2e-4,\n        lr_scheduler_type=\"cosine\",\n        #EvaluationStrategy = \"steps\",\n        save_strategy=\"epoch\",\n        logging_steps=30,\n        max_steps=-1,\n        num_train_epochs=2,\n        report_to=\"wandb\"\n    )","metadata":{"execution":{"iopub.status.busy":"2024-08-25T10:17:07.575736Z","iopub.execute_input":"2024-08-25T10:17:07.576082Z","iopub.status.idle":"2024-08-25T10:17:07.605930Z","shell.execute_reply.started":"2024-08-25T10:17:07.576047Z","shell.execute_reply":"2024-08-25T10:17:07.604886Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    train_dataset=tokenized_training_data[\"input_ids\"],\n    args=training_arguments,\n    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T10:17:07.607501Z","iopub.execute_input":"2024-08-25T10:17:07.608255Z","iopub.status.idle":"2024-08-25T10:17:08.080195Z","shell.execute_reply.started":"2024-08-25T10:17:07.608204Z","shell.execute_reply":"2024-08-25T10:17:08.079066Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#Training\ntrainer.train()\ntrainer.model.save_pretrained(new_model)\nmodel.config.use_cache = True\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T10:17:08.081463Z","iopub.execute_input":"2024-08-25T10:17:08.081873Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='27' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 27/500 02:23 < 45:09, 0.17 it/s, Epoch 0.10/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"def phi_stream(prompt):\n    runtimeFlag = \"cuda:0\"\n    \n    # Tokenize the input with attention mask and padding\n    inputs = tokenizer(\n        f'''Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{prompt}\\n\\n### Response:\\n''', \n        return_tensors=\"pt\", \n        return_attention_mask=True,\n        padding=True\n    ).to(runtimeFlag)\n    \n    # Set the pad_token_id to avoid warnings\n    pad_token_id = tokenizer.eos_token_id\n    \n    streamer = TextStreamer(tokenizer, skip_prompt=True)\n    \n    # Generate the response\n    _ = model.generate(\n        **inputs, \n        streamer=streamer, \n        max_new_tokens=100,\n        pad_token_id=pad_token_id\n    )\n\n# Test the function with a single task\nphi_stream(\"computer\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"phi_stream(\"p-n junction diode\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"phi_stream(\"Avalanche diode \")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}